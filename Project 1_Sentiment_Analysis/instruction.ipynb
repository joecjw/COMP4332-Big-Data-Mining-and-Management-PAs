{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6u-Pk-Xb5UJH"
   },
   "source": [
    "# Instructions for Project 1 - Sentiment Analysis\n",
    "\n",
    "Hello everyone, this is Zhaowei Wang. I am glad to host the first project. My email is *zwanggy@connect.ust.hk*. Feel free to send me an email if you have any problem regarding this project.\n",
    "\n",
    "In this project, you will try to work on a sentiment analysis task.\n",
    "You will build a model to predict the scores (a.k.a. the \"label\" column in datasets, from 1 to 5) of each review.\n",
    "For each review, you are given a piece of text. You can consider the predicted variables as categorical, ordinal or numerical.\n",
    "\n",
    "Just a kind note: The codes and techniques introduced in the previous tutorials may come in handy. You can refer to the .ipynb notebooks for details.\n",
    "\n",
    "## Important dates, submission requirements and grading policy \n",
    "**Important dates:**\n",
    "- *March 16, 2024 (Saturday)*: Project starts\n",
    "- *March 23, 2024 (Saturday)* Release the validation score of baselines\n",
    "- *April 6, 2024, 23:59 (Saturday)*: `Submission Deadline`\n",
    "\n",
    "**Submission requirements:**  \n",
    "Each team leader is required to submit the groupNo.zip file on the Canvas. It shoud contain \n",
    "- `pred.csv`: Predictions on test data (please make sure you can successfully evaluate your validation predictions on the validation data with the help of evaluate.py). The file should contain two so-called columns, which are `id`\n",
    "and `label`.\n",
    "- report (1-2 pages of pdf)\n",
    "- code (Frameworks and programming languages are not restricted)\n",
    "\n",
    "**Grading policy:**  \n",
    "We will check your report with your code and your model performance (in terms of Accuracy) on the test set.\n",
    "\n",
    "| Grade | Classifier (80%)                                                   | Report (20%)                      |\n",
    "|-------|--------------------------------------------------------------------|-----------------------------------|\n",
    "| 50%   | Example code in tutorials or in Project 1 without any modification | submission                        |\n",
    "| 75%   | A method that can outperform the easy baseline  | algorithm you used                |\n",
    "| 95%   | A method that can outperform the hard baseline                     | detailed explanation and analysis, such as explorative data analysis, hyperparameters and ablation studies  |\n",
    "| 100%  | A method that can outperform the hard baseline with at least one excellent idea  | excellent ideas, detailed explanation and solid analysis |\n",
    "\n",
    "## Instruction Content\n",
    "In this notebook, you are provided with the code snippets to start with.\n",
    "\n",
    "The content follows previous lectures and tutorials. But some potentially useful python packages are also mentioned.\n",
    "\n",
    "1. Loading data and saving predictions\n",
    "    1. Loading data\n",
    "    1. Saving predictions to file\n",
    "1. Preprocessing\n",
    "    1. Text data processing recap\n",
    "    1. Explorative data analysis\n",
    "1. Learning Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpoRui_47pOQ"
   },
   "source": [
    "## 1. Loading data and saving predictions\n",
    "\n",
    "The same as previous tutorials, we use `pandas` as the basic tool to load & dump the data.\n",
    "The key ingredient of our operation is the `DataFrame` in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1678609678007,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "56Yveell5UJM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V9e5rcOs77K9"
   },
   "outputs": [],
   "source": [
    "# if you use Google Colab, un-comment this cell, modify `path_to_data` if needed, and run to mount data to `data`\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# path_to_data = '/content/drive/MyDrive/HKUST stuff/COMP4332_Project1/data'\n",
    "# !rm -f data\n",
    "# !ln -s '/content/drive/MyDrive/HKUST stuff/COMP4332_Project1/data' data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo8Z7VVq5UJO"
   },
   "source": [
    "### A. Loading data\n",
    "\n",
    "The following code shows how to load the datasets for this project.  \n",
    "Among which, we do not release the labels (the \"label\" column) for the test set. \n",
    "You may evaluate your trained model on the validation set instead.\n",
    "However, your submitted predictions (``pred.csv``) should be generated on the test set.\n",
    "\n",
    "Each year we release different data, so old models are not guaranteed to solve the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1678609870255,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "coz-oCwS5UJP"
   },
   "outputs": [],
   "source": [
    "def load_data(split_name='train', columns=['text', 'label'], folder='data'):\n",
    "    '''\n",
    "        \"split_name\" may be set as 'train', 'valid' or 'test' to load the corresponding dataset.\n",
    "        \n",
    "        You may also specify the column names to load any columns in the .csv data file.\n",
    "        Among many, \"text\" can be used as model input, and \"label\" column is the labels (sentiment). \n",
    "    '''\n",
    "    try:\n",
    "        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        df = df.loc[:,columns]\n",
    "        print(\"Success\")\n",
    "        return df\n",
    "    except:\n",
    "        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n",
    "        df = pd.read_csv(f'{folder}/{split_name}.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJnx8k_s5UJQ"
   },
   "source": [
    "Then you can extract the data by specifying the desired split and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3087,
     "status": "ok",
     "timestamp": 1678609875903,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "UEJmxylT5UJR",
    "outputId": "599a719c-2f0b-425b-a76f-26f5a2aae895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [text, label] columns from the valid split\n",
      "Success\n",
      "select [id, text] columns from the test_no_label split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train', columns=['text', 'label'], folder='data')\n",
    "valid_df = load_data('valid', columns=['text', 'label'], folder='data')\n",
    "# the test set labels (the 'label' column) are unavailable! So the following code will instead return all columns\n",
    "test_df = load_data('test_no_label', columns=['id', 'text'], folder='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1678609899213,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "TuA-yimg5UJS",
    "outputId": "81bca1db-177c-4182-9d8d-a19310decbbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two Wolfgang Petersen directed films together ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For fans of the series and the movies\\nthis fi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love the movie. The Blu-ray was fine, but it...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You don't know what is going on until the end ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We only watched a few minutes of the movie, du...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Two Wolfgang Petersen directed films together ...      5\n",
       "1  For fans of the series and the movies\\nthis fi...      4\n",
       "2  I love the movie. The Blu-ray was fine, but it...      3\n",
       "3  You don't know what is going on until the end ...      3\n",
       "4  We only watched a few minutes of the movie, du...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1678609946432,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "ZKc0Sllc5UJS",
    "outputId": "e6ec52bc-726f-450d-ad2f-131193086481"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EMGD8RAEOK64_2907</td>\n",
       "      <td>On our trip this past summer to Lunenberg, Nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2BOWU2PX28BET_5501</td>\n",
       "      <td>Excellent!! Most remakes fall short of the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A100WO06OQR8BQ_10469</td>\n",
       "      <td>I started to watch this movie but it is such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2H4LKU7CPIUU9_11364</td>\n",
       "      <td>Well! I must be terribly jaded. Or I am comple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14RF11JYGDKI8_23751</td>\n",
       "      <td>Dark and grim -- not a fun movie.  Watch it fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text\n",
       "0   A3EMGD8RAEOK64_2907  On our trip this past summer to Lunenberg, Nov...\n",
       "1   A2BOWU2PX28BET_5501  Excellent!! Most remakes fall short of the ori...\n",
       "2  A100WO06OQR8BQ_10469  I started to watch this movie but it is such a...\n",
       "3  A2H4LKU7CPIUU9_11364  Well! I must be terribly jaded. Or I am comple...\n",
       "4  A14RF11JYGDKI8_23751  Dark and grim -- not a fun movie.  Watch it fo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1678610237266,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "LFfewsiX5UJT",
    "outputId": "20c456e7-2f7b-4844-9fdd-5b9a0d6bb389"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000 2000 4000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(valid_df), len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mef_BG-X5UJT"
   },
   "source": [
    "### B. Saving predictions to file\n",
    "\n",
    "Your submitted predictions are supposed to be a .csv file containing two columns, i.e. (``id`` and ``label``). \n",
    "\n",
    "Here, as an example, we generate some random predictions as our answer, which are put in a DataFrame and output to a .csv file\n",
    "\n",
    "After getting your model predictions on the test set, you may follow these steps to generate your ``pred.csv`` file. (By replacing the random predictions with your model predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1678610430357,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "5AmFZ96x5UJU"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1678610430934,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "HwYfkZvU5UJU"
   },
   "outputs": [],
   "source": [
    "random_pred = pd.DataFrame(data={\n",
    "    'id': test_df['id'],\n",
    "    'label': np.random.randint(0, 6, size=len(test_df))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1678610431694,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "jGGl8Kt85UJU",
    "outputId": "72ec1c3d-6a0d-4daf-b9af-849a7a1e8773"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EMGD8RAEOK64_2907</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2BOWU2PX28BET_5501</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A100WO06OQR8BQ_10469</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2H4LKU7CPIUU9_11364</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A14RF11JYGDKI8_23751</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  label\n",
       "0   A3EMGD8RAEOK64_2907      2\n",
       "1   A2BOWU2PX28BET_5501      0\n",
       "2  A100WO06OQR8BQ_10469      4\n",
       "3  A2H4LKU7CPIUU9_11364      2\n",
       "4  A14RF11JYGDKI8_23751      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1678610434485,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "XMBpLyd35UJU"
   },
   "outputs": [],
   "source": [
    "random_pred.to_csv(f'random_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb1ZhmEZ5UJV"
   },
   "source": [
    "Then, you will get a ``random_pred.csv`` in your folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7lkS6sqAIT0"
   },
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Here are some preprocessing examples for your reference. For more details you may refer to the previous tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luZkHLq35UJV"
   },
   "source": [
    "### A. Text data processing recap\n",
    "In the tutorials, we have shown how to extract textual features using the `nltk` package\n",
    "\n",
    "Remember to use the NLTK Downloader to obtain the resource first:\n",
    "```\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('stopwords')\n",
    "  >>> nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1678610498614,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "a-KE25vc5UJV"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def lower(s):\n",
    "    \"\"\"\n",
    "    :param s: a string.\n",
    "    return a string with lower characters\n",
    "    Note that we allow the input to be nested string of a list.\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: 'text mining is to identify useful information.'\n",
    "    \"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return [lower(t) for t in s]\n",
    "    if isinstance(s, str):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        raise NotImplementedError(\"unknown datatype\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     results.append(ps.stem(token))\n",
    "    # return results\n",
    "\n",
    "    return [ps.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    ### equivalent code\n",
    "    # results = list()\n",
    "    # for token in tokens:\n",
    "    #     if token not in stopwords and not token.isnumeric():\n",
    "    #         results.append(token)\n",
    "    # return results\n",
    "\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeAOeeYC5UJW"
   },
   "source": [
    "Note that you can use the `map` function to apply your preprocessing functions into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_df)):\n",
    "    try:\n",
    "        tokenize(test_df.loc[i, 'text'])\n",
    "    except: \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                     A8NQVLIE0QVT4_7949\n",
      "text    Great movie, even better dubb. Blu ray is the ...\n",
      "Name: 1155, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test_df.loc[1155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6268,
     "status": "ok",
     "timestamp": 1678610507492,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "hei6VERQ5UJW",
    "outputId": "94858015-82ba-4203-e52d-2d7e68a7c8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [on, trip, past, summer, lunenberg, ,, nova, s...\n",
      "1    [excellent, !, !, most, remakes, fall, short, ...\n",
      "2    [i, started, watch, movie, lousy, movie, i, st...\n",
      "3    [well, !, i, must, terribly, jaded, ., or, i, ...\n",
      "4    [dark, grim, --, fun, movie, ., watch, perform...\n"
     ]
    }
   ],
   "source": [
    "test_df['tokens'] = test_df['text'].map(tokenize).map(filter_stopwords).map(lower)\n",
    "print(test_df['tokens'].head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2aF74qi5UJW"
   },
   "source": [
    "Besides `nltk`, `SpaCy` may also be useful.\n",
    "\n",
    "You can explore it at https://spacy.io/\n",
    "\n",
    "Let's install it with the following command (in terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTFX-QsE5UJX"
   },
   "source": [
    "```bash\n",
    "python -m pip install spacy\n",
    "python -m spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21234,
     "status": "ok",
     "timestamp": 1678610588751,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "tGU6YJjN5UJX",
    "outputId": "cfec0f6b-888a-48e4-fcc8-d372973a54b7"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCLmErA45UJX"
   },
   "source": [
    "You may use spacy to extract linguistic features from texts\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 289,
     "status": "ok",
     "timestamp": 1678610605522,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "kZz4vWC85UJX",
    "outputId": "0864667b-3dab-46c2-ca4b-83761fad340f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw       ,\t stem      ,\t PartOfSpeech,\t dependency,\t shape     ,\t is alpha  ,\t is stop   ,\t its childrens in the parsing tree,\t \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Apple     ,\t Apple     ,\t PROPN     ,\t nsubj     ,\t Xxxxx     ,\t True      ,\t False     ,\t []        ,\t \n",
      "is        ,\t be        ,\t AUX       ,\t aux       ,\t xx        ,\t True      ,\t True      ,\t []        ,\t \n",
      "looking   ,\t look      ,\t VERB      ,\t ROOT      ,\t xxxx      ,\t True      ,\t False     ,\t [Apple, is, at, startup],\t \n",
      "at        ,\t at        ,\t ADP       ,\t prep      ,\t xx        ,\t True      ,\t True      ,\t [buying]  ,\t \n",
      "buying    ,\t buy       ,\t VERB      ,\t pcomp     ,\t xxxx      ,\t True      ,\t False     ,\t [U.K.]    ,\t \n",
      "U.K.      ,\t U.K.      ,\t PROPN     ,\t dobj      ,\t X.X.      ,\t False     ,\t False     ,\t []        ,\t \n",
      "startup   ,\t startup   ,\t NOUN      ,\t dep       ,\t xxxx      ,\t True      ,\t False     ,\t [for]     ,\t \n",
      "for       ,\t for       ,\t ADP       ,\t prep      ,\t xxx       ,\t True      ,\t True      ,\t [billion] ,\t \n",
      "$         ,\t $         ,\t SYM       ,\t quantmod  ,\t $         ,\t False     ,\t False     ,\t []        ,\t \n",
      "1         ,\t 1         ,\t NUM       ,\t compound  ,\t d         ,\t False     ,\t False     ,\t []        ,\t \n",
      "billion   ,\t billion   ,\t NUM       ,\t pobj      ,\t xxxx      ,\t True      ,\t False     ,\t [$, 1]    ,\t \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "fmt = \"{:10s},\\t \" * 8\n",
    "print(fmt.format('raw', 'stem', 'PartOfSpeech', 'dependency', 'shape', 'is alpha', 'is stop', 'its childrens in the parsing tree'))\n",
    "print('-'*140)\n",
    "for token in doc:\n",
    "    print(fmt.format(token.text, token.lemma_, token.pos_, token.dep_,\n",
    "            token.shape_, str(token.is_alpha), str(token.is_stop), str(list(token.children))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9y6cC-m5UJX"
   },
   "source": [
    "SpaCy also allows you to use the embeddings for both sentence and words\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1678610609505,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "HQXuIT-i5UJY",
    "outputId": "0c2b6639-827b-42bd-bef0-1ac161b62ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking at buying U.K. startup for $1 billion [-0.49226812  0.40478638  0.5446301   0.2650897   0.5588461 ] ...\n",
      "Apple [-1.231103   -1.1917272   0.15840513  0.3598817   0.680532  ] ...\n",
      "is [-1.0020912  -0.24935524  0.2847814   0.7584369  -0.5807612 ] ...\n",
      "looking [-0.3423702  1.0666494  0.7334783  0.0921919 -1.0159137] ...\n",
      "at [ 1.4327683   1.9650179   0.528621   -1.103754   -0.29277676] ...\n",
      "buying [ 0.21374054  0.97006285 -0.37104425  0.25935912 -0.5281231 ] ...\n",
      "U.K. [-0.4769047 -0.6881261 -1.0802059  0.9870316  1.3138596] ...\n",
      "startup [-0.7687981   0.16186625  0.20556203 -0.70367986 -0.56370217] ...\n",
      "for [-0.12731966  0.20830332  1.3329215  -0.43356493 -0.7824546 ] ...\n",
      "$ [-0.5493651   1.2996746   0.19532208  0.46639207  1.8706077 ] ...\n",
      "1 [-1.1942618   0.7871655   5.5716734   0.19170347  3.1280797 ] ...\n",
      "billion [-1.3692445   0.12311826 -1.568583    2.0419886   2.91796   ] ...\n"
     ]
    }
   ],
   "source": [
    "print(doc, doc.vector[:5], '...')\n",
    "for t in doc:\n",
    "    print(t, t.vector[:5], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFBq_0Xe5UJY"
   },
   "source": [
    "For more usage of SpaCy, you can refer to its documentation at this link: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75a7A16B5UJa"
   },
   "source": [
    "## 2. Baselines\n",
    "\n",
    "Finally, we provide two example baselines for your reference. The first baseline extracts TF-iDF features from texts and use logistic regression to generate prediction. The second baseline uses Convolutional Neural Networks (CNNs) to generate prediction from texts.\n",
    "\n",
    "\n",
    "We only consider its first 3k training samples. It is just an example, you can use the data as you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpeYkRdXAOHl"
   },
   "source": [
    "### TF-IDF + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1678610733934,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "s8XXemtF5UJa"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567,
     "status": "ok",
     "timestamp": 1678610735689,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "N5AKPx2A5UJb",
    "outputId": "99c341c9-55bc-47d8-fa0d-341d9554c63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select [text, label] columns from the train split\n",
      "Success\n",
      "select [text, label] columns from the valid split\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data('train')[:3000]\n",
    "valid_df = load_data('valid')\n",
    "x_train = train_df['text']\n",
    "y_train = train_df['label']\n",
    "x_valid = valid_df['text']\n",
    "y_valid = valid_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1678610741896,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "NooKm1m75UJb",
    "outputId": "d4aa30ed-f95b-4ef8-dcf2-7c290c5751fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(tokenizer=<function tokenize at 0x7feaa9f41160>)),\n",
      "                ('lr', LogisticRegression())])\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize)\n",
    "lr = LogisticRegression()\n",
    "steps = [('tfidf', tfidf),('lr', lr)]\n",
    "pipe = Pipeline(steps)\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "executionInfo": {
     "elapsed": 19070,
     "status": "ok",
     "timestamp": 1678610762673,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "Xrav6WYa5UJb",
    "outputId": "69ff5979-9e95-4129-cafc-da279576040d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7feaa9f41160&gt;)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7feaa9f41160&gt;)),\n",
       "                (&#x27;lr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(tokenizer=&lt;function tokenize at 0x7feaa9f41160&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(tokenizer=<function tokenize at 0x7feaa9f41160>)),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3697,
     "status": "ok",
     "timestamp": 1678610766310,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "sjSUgqGJ5UJb",
    "outputId": "970fc723-6ff2-4086-db87-d50cb0a9b780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.38      0.46       295\n",
      "           2       0.53      0.10      0.16       198\n",
      "           3       0.42      0.60      0.49       508\n",
      "           4       0.42      0.36      0.38       523\n",
      "           5       0.52      0.66      0.58       476\n",
      "\n",
      "    accuracy                           0.47      2000\n",
      "   macro avg       0.49      0.42      0.42      2000\n",
      "weighted avg       0.48      0.47      0.45      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[112  13  98  33  39]\n",
      " [ 35  19 105  23  16]\n",
      " [ 20   4 303 118  63]\n",
      " [ 12   0 157 186 168]\n",
      " [ 14   0  62  88 312]]\n",
      "accuracy 0.466\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(x_valid)\n",
    "print(classification_report(y_valid, y_pred))\n",
    "print(\"\\n\\n\")\n",
    "print(confusion_matrix(y_valid, y_pred))\n",
    "print('accuracy', np.mean(y_valid == y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZMSn0Hy5UJb"
   },
   "source": [
    "### CNN\n",
    "\n",
    "The second baseline is a CNN model implemented with PyTorch.\n",
    "\n",
    "First, use the following command to install pytorch (in terminal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n2fiogb5UJc"
   },
   "source": [
    "```bash\n",
    "pip install torch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1678610803799,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "70WhNXeX5UJc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 23206,
     "status": "ok",
     "timestamp": 1678610943576,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "NWEZApuy5UJc"
   },
   "outputs": [],
   "source": [
    "train_text = train_df['text'].map(tokenize).map(filter_stopwords).map(stem)\n",
    "valid_text = valid_df['text'].map(tokenize).map(filter_stopwords).map(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1678610943578,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "nWvH-WcZ5UJc"
   },
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "for tokens in train_text:\n",
    "    for t in tokens:\n",
    "        if not t in word2id:\n",
    "            word2id[t] = len(word2id)\n",
    "word2id['<pad>'] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1678610943579,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "020Rz3xi5UJc"
   },
   "outputs": [],
   "source": [
    "def texts_to_id_seq(texts, padding_length=50):\n",
    "    records = []\n",
    "    for tokens in texts:\n",
    "        record = []\n",
    "        for t in tokens:\n",
    "            record.append(word2id.get(t, len(word2id)))\n",
    "        if len(record) >= padding_length:\n",
    "            records.append(record[:padding_length])\n",
    "        else:\n",
    "            records.append(record + [word2id['<pad>']] * (padding_length - len(record)))\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1678610943580,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "0lT2tV3g5UJc"
   },
   "outputs": [],
   "source": [
    "train_seqs = texts_to_id_seq(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1678610944024,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "sHB6Ud3v5UJd"
   },
   "outputs": [],
   "source": [
    "valid_seqs = texts_to_id_seq(valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1678610944026,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "aubFZ3Mg5UJd"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq, y):\n",
    "        assert len(seq) == len(y)\n",
    "        self.seq = seq\n",
    "        self.y = y-1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return np.asarray(self.seq[idx]), self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1678610944030,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "P1UXP-p15UJd"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(MyDataset(train_seqs, y_train), batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(MyDataset(valid_seqs, y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1678610944031,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "jPCHEnSB5UJd"
   },
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(word2id)+1, embedding_dim=64)\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1),\n",
    "            nn.MaxPool1d(kernel_size=3, stride=1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.linear = nn.Linear(64, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = self.cnn(x)\n",
    "        x = torch.max(x, dim=-1)[0]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1678610944033,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "niiGxZzO5UJd"
   },
   "outputs": [],
   "source": [
    "model = mlp()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 304128,
     "status": "ok",
     "timestamp": 1678611248121,
     "user": {
      "displayName": "Azir",
      "userId": "14152163960880447733"
     },
     "user_tz": -480
    },
    "id": "nZHul4x_5UJe",
    "outputId": "6be5adf2-a97a-44a6-9fc1-8cb10fafe5ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 123.20it/s, loss=0.0982, acc=0.281]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 529.53it/s]\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.01      0.01       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.33      0.25      0.28       508\n",
      "           3       0.28      0.02      0.04       523\n",
      "           4       0.26      0.87      0.40       476\n",
      "\n",
      "    accuracy                           0.28      2000\n",
      "   macro avg       0.20      0.23      0.15      2000\n",
      "weighted avg       0.24      0.28      0.18      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[  2   0  67   7 219]\n",
      " [  1   0  50   0 147]\n",
      " [  5   0 126  16 361]\n",
      " [  3   0  87  10 423]\n",
      " [  6   0  55   3 412]]\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.25it/s, loss=0.0894, acc=0.392]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.70it/s]\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wangzhaowei/opt/anaconda3/envs/COMP4332/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.15      0.21       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.31      0.35      0.33       508\n",
      "           3       0.30      0.56      0.39       523\n",
      "           4       0.47      0.33      0.39       476\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.29      0.28      0.26      2000\n",
      "weighted avg       0.32      0.34      0.31      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 45   0 116 104  30]\n",
      " [ 15   0  89  75  19]\n",
      " [ 30   0 177 263  38]\n",
      " [ 22   0 120 294  87]\n",
      " [ 14   0  76 230 156]]\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 138.02it/s, loss=0.0781, acc=0.495]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 532.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.15      0.22       295\n",
      "           1       0.00      0.00      0.00       198\n",
      "           2       0.29      0.79      0.42       508\n",
      "           3       0.34      0.15      0.21       523\n",
      "           4       0.57      0.31      0.40       476\n",
      "\n",
      "    accuracy                           0.34      2000\n",
      "   macro avg       0.32      0.28      0.25      2000\n",
      "weighted avg       0.36      0.34      0.29      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 45   0 227  14   9]\n",
      " [ 15   0 169   9   5]\n",
      " [ 19   0 402  63  24]\n",
      " [ 13   0 355  80  75]\n",
      " [ 22   1 233  71 149]]\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 137.92it/s, loss=0.0649, acc=0.595]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.45      0.35       295\n",
      "           1       0.23      0.12      0.15       198\n",
      "           2       0.33      0.32      0.33       508\n",
      "           3       0.29      0.19      0.23       523\n",
      "           4       0.42      0.51      0.46       476\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.31      0.32      0.30      2000\n",
      "weighted avg       0.32      0.33      0.32      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[134  26  73  27  35]\n",
      " [ 70  23  57  21  27]\n",
      " [122  32 165  97  92]\n",
      " [ 91  14 133  99 186]\n",
      " [ 60   5  72  94 245]]\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.22it/s, loss=0.0493, acc=0.718]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 535.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.34      0.33       295\n",
      "           1       0.21      0.26      0.23       198\n",
      "           2       0.33      0.31      0.32       508\n",
      "           3       0.34      0.39      0.36       523\n",
      "           4       0.50      0.38      0.43       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.34      0.34      0.33      2000\n",
      "weighted avg       0.36      0.35      0.35      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[100  58  62  51  24]\n",
      " [ 44  52  62  27  13]\n",
      " [ 79  72 158 157  42]\n",
      " [ 53  48 116 202 104]\n",
      " [ 42  17  76 160 181]]\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 132.51it/s, loss=0.0345, acc=0.818]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 537.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.32      0.32       295\n",
      "           1       0.30      0.09      0.13       198\n",
      "           2       0.32      0.54      0.40       508\n",
      "           3       0.31      0.11      0.17       523\n",
      "           4       0.42      0.52      0.47       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.33      0.32      0.30      2000\n",
      "weighted avg       0.34      0.35      0.32      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 95  16 130  10  44]\n",
      " [ 44  17 102   6  29]\n",
      " [ 71  13 276  56  92]\n",
      " [ 49   7 236  60 171]\n",
      " [ 38   3 127  61 247]]\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 141.04it/s, loss=0.0227, acc=0.894]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 534.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.35      0.33       295\n",
      "           1       0.20      0.07      0.10       198\n",
      "           2       0.32      0.49      0.39       508\n",
      "           3       0.32      0.20      0.25       523\n",
      "           4       0.45      0.47      0.46       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.32      0.32      0.31      2000\n",
      "weighted avg       0.34      0.35      0.33      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[103  20 115  23  34]\n",
      " [ 53  14  92  14  25]\n",
      " [ 75  23 250  84  76]\n",
      " [ 59  10 208 107 139]\n",
      " [ 39   4 109 102 222]]\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 144.16it/s, loss=0.0131, acc=0.954]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 531.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.32      0.32       295\n",
      "           1       0.26      0.11      0.16       198\n",
      "           2       0.33      0.39      0.36       508\n",
      "           3       0.33      0.44      0.38       523\n",
      "           4       0.52      0.35      0.42       476\n",
      "\n",
      "    accuracy                           0.36      2000\n",
      "   macro avg       0.35      0.32      0.33      2000\n",
      "weighted avg       0.37      0.36      0.35      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 93  24  96  61  21]\n",
      " [ 45  22  76  40  15]\n",
      " [ 65  21 200 184  38]\n",
      " [ 47  12 150 230  84]\n",
      " [ 33   5  85 185 168]]\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 188/188 [00:01<00:00, 135.59it/s, loss=0.0089, acc=0.967]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 538.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.28      0.31       295\n",
      "           1       0.21      0.18      0.20       198\n",
      "           2       0.31      0.56      0.40       508\n",
      "           3       0.34      0.27      0.30       523\n",
      "           4       0.59      0.30      0.40       476\n",
      "\n",
      "    accuracy                           0.35      2000\n",
      "   macro avg       0.36      0.32      0.32      2000\n",
      "weighted avg       0.38      0.35      0.34      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 83  40 137  22  13]\n",
      " [ 31  36 109  15   7]\n",
      " [ 54  50 287  98  19]\n",
      " [ 39  32 247 143  62]\n",
      " [ 38  13 142 138 145]]\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 188/188 [00:01<00:00, 139.29it/s, loss=0.00522, acc=0.987]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 536.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.46      0.34       295\n",
      "           1       0.23      0.18      0.20       198\n",
      "           2       0.32      0.24      0.28       508\n",
      "           3       0.32      0.34      0.33       523\n",
      "           4       0.46      0.39      0.42       476\n",
      "\n",
      "    accuracy                           0.33      2000\n",
      "   macro avg       0.32      0.32      0.31      2000\n",
      "weighted avg       0.34      0.33      0.33      2000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[135  37  54  42  27]\n",
      " [ 72  36  45  28  17]\n",
      " [131  49 123 149  56]\n",
      " [ 97  29 100 177 120]\n",
      " [ 68   9  60 152 187]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, 11):    \n",
    "    print('epoch', e)\n",
    "    model.train()\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    total_count = 0\n",
    "    with tqdm.tqdm(train_loader) as t:\n",
    "        for x, y in t:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += y.size(0)\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            t.set_postfix({'loss': total_loss/total_count, 'acc': total_acc/total_count})\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with tqdm.tqdm(valid_loader) as t:\n",
    "        for x, y in t:\n",
    "            logits = model(x)\n",
    "            total_acc += (logits.argmax(1) == y).sum().item()\n",
    "            total_count += len(y)\n",
    "            y_pred += logits.argmax(1).tolist()\n",
    "            y_true += y.tolist()\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\n\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I2bb-SbT5UJe"
   },
   "source": [
    "Deep learning are full of tricks. \n",
    "\n",
    "In the second example above, the CNN baseline is even not good enough to beat the TFIDF+Logistic regression baseline.\n",
    "\n",
    "You can use all the techniques introduced in the lectures and tutorials to enhance your methods.\n",
    "\n",
    "Of course, you can try any other ideas to make your model distinguished.\n",
    "\n",
    "Also, if you want to use pre-trained models. here are some reference content:\n",
    "1. https://huggingface.co/docs/transformers/tasks/sequence_classification\n",
    "2. https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
