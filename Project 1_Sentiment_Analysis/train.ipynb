{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:13.449184Z","iopub.status.busy":"2024-03-30T17:23:13.448562Z","iopub.status.idle":"2024-03-30T17:23:17.954063Z","shell.execute_reply":"2024-03-30T17:23:17.953113Z","shell.execute_reply.started":"2024-03-30T17:23:13.449148Z"},"id":"ZH_G7uQXmNGj","trusted":true},"outputs":[],"source":["import tqdm\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertModel\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","from prettytable import PrettyTable\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","metadata":{},"source":["### Load and Preapre data for training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:17.956698Z","iopub.status.busy":"2024-03-30T17:23:17.956163Z","iopub.status.idle":"2024-03-30T17:23:18.043183Z","shell.execute_reply":"2024-03-30T17:23:18.042104Z","shell.execute_reply.started":"2024-03-30T17:23:17.956664Z"},"id":"yFzaeUqLmNGn","trusted":true},"outputs":[],"source":["def load_data(split_name='train', columns=['text', 'label'], folder='data'):\n","    try:\n","        print(f\"select [{', '.join(columns)}] columns from the {split_name} split\")\n","        df = pd.read_csv(f'{folder}/{split_name}.csv')\n","        df = df.loc[:,columns]\n","        print(\"Success\")\n","        return df\n","    except:\n","        print(f\"Failed loading specified columns... Returning all columns from the {split_name} split\")\n","        df = pd.read_csv(f'{folder}/{split_name}.csv')\n","        return df\n","\n","train_df = load_data('train', columns=['text', 'label'], folder='data')\n","valid_df = load_data('valid', columns=['text', 'label'], folder='data')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:18.045357Z","iopub.status.busy":"2024-03-30T17:23:18.044787Z","iopub.status.idle":"2024-03-30T17:23:18.361961Z","shell.execute_reply":"2024-03-30T17:23:18.360988Z","shell.execute_reply.started":"2024-03-30T17:23:18.045322Z"},"id":"5-jdWDyysM3A","trusted":true},"outputs":[],"source":["max_len = 256\n","class_num = 5\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","class Train_Valid_Dataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.dataframe = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __getitem__(self, index):\n","        row = self.dataframe.iloc[index]\n","        text = row['text']\n","        inputs = self.tokenizer.encode_plus(text,\n","                                            add_special_tokens=True,\n","                                            max_length=self.max_len,\n","                                            padding='max_length', \n","                                            truncation=True,\n","                                            return_attention_mask=True,\n","                                            return_tensors='pt')\n","        target = torch.zeros(class_num)\n","        target[row['label']-1] = 1.\n","        return {\n","            'input_ids':inputs['input_ids'].flatten(),\n","            'attention_mask':inputs['attention_mask'].flatten(),\n","            'token_type_ids':inputs['token_type_ids'].flatten(),\n","            'labels': target\n","        }\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","train_dataset = Train_Valid_Dataset(dataframe=train_df, tokenizer=tokenizer, max_len=max_len)\n","valid_dataset = Train_Valid_Dataset(dataframe=valid_df, tokenizer=tokenizer, max_len=max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:18.363700Z","iopub.status.busy":"2024-03-30T17:23:18.363327Z","iopub.status.idle":"2024-03-30T17:23:18.368794Z","shell.execute_reply":"2024-03-30T17:23:18.367873Z","shell.execute_reply.started":"2024-03-30T17:23:18.363669Z"},"trusted":true},"outputs":[],"source":["batch_size = 16\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Prepare model for training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:18.372180Z","iopub.status.busy":"2024-03-30T17:23:18.371887Z","iopub.status.idle":"2024-03-30T17:23:19.199470Z","shell.execute_reply":"2024-03-30T17:23:19.198585Z","shell.execute_reply.started":"2024-03-30T17:23:18.372157Z"},"id":"6eluqbbKmNGq","trusted":true},"outputs":[],"source":["class SAM(nn.Module):\n","    def __init__(self, class_num):\n","        super(SAM, self).__init__()\n","        self.class_num = class_num\n","        self.max_len = 256\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","        self.pretrained_model = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n","        self.linear = nn.Linear(768, self.class_num, bias=True)\n","        self.loss_fnc = nn.CrossEntropyLoss()\n","        \n","    def load_checkpoint(self, checkpoint_path=None):\n","        if(checkpoint_path):\n","            checkpoint = torch.load(checkpoint_path)\n","            self.load_state_dict(checkpoint['model'])\n","        \n","    def forward(self, samples):\n","        output = self.pretrained_model(samples['input_ids'].to(device, dtype=torch.long),\n","                                      samples['attention_mask'].to(device, dtype=torch.long),\n","                                      samples['token_type_ids'].to(device, dtype=torch.long))\n","        logits = self.linear(output.pooler_output)\n","        loss = self.loss_fnc(logits, samples['labels'].to(device, dtype=torch.float))\n","        return {'logits':logits, 'loss':loss}\n","\n","    def predict(self, text):\n","        inputs = self.tokenizer.encode_plus(text,\n","                                            add_special_tokens=True,\n","                                            max_length=self.max_len,\n","                                            padding='max_length', \n","                                            truncation=True,\n","                                            return_attention_mask=True,\n","                                            return_tensors='pt')\n","        with torch.no_grad():\n","            output = self.pretrained_model(inputs['input_ids'].flatten().to(device, dtype=torch.long),\n","                                  inputs['attention_mask'].flatten().to(device, dtype=torch.long),\n","                                  inputs['token_type_ids'].flatten().to(device, dtype=torch.long))\n","        logits = self.linear(output.pooler_output)\n","        print(logits)\n","        print(logits[0])\n","        print(logits[0].softmax(1))\n","        print(logits[0].softmax(1).argmax())\n","        label = logits[0].softmax(1).argmax() + 1\n","        return {'label': label}\n","    \n","def count_trainable_parameters(model):\n","    table = PrettyTable([\"Modules\", \"Parameters\"])\n","    total_params = 0\n","    for name, parameter in model.named_parameters():\n","        if not parameter.requires_grad:\n","            continue\n","        params = parameter.numel()\n","        table.add_row([name, params])\n","        total_params += params\n","    print(table)\n","    print(f\"Total Trainable Params: {total_params}\")\n","    return total_params\n","        \n","        \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n","model = SAM(class_num=class_num)\n","model.to(device)\n","#count_trainable_parameters(model)"]},{"cell_type":"markdown","metadata":{},"source":["### Define training code and train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:19.200863Z","iopub.status.busy":"2024-03-30T17:23:19.200591Z","iopub.status.idle":"2024-03-30T17:23:19.214218Z","shell.execute_reply":"2024-03-30T17:23:19.213295Z","shell.execute_reply.started":"2024-03-30T17:23:19.200841Z"},"id":"mnGgH6LNmNGr","outputId":"4537a28d-00bb-457d-e748-d96b589365c7","trusted":true},"outputs":[],"source":["def train(num_epoch, train_loader, valid_loader, model, optimizer):\n","    for epoch in range(num_epoch):\n","        print(\"\\n\")\n","        print(f'epoch:{epoch+1}')\n","        model.train()  \n","        count = 0\n","        train_loss = 0\n","        train_accuracy = 0\n","        train_bar = tqdm.tqdm(train_loader)\n","        for i, samples in enumerate(train_bar):\n","            optimizer.zero_grad()\n","            output = model(samples)\n","            logits = output['logits']\n","            loss = output['loss']\n","            loss.backward()\n","            optimizer.step()\n","            \n","            count += samples['labels'].size(0)\n","            train_loss += loss.item()\n","            train_acc = accuracy_score(samples['labels'].argmax(-1).cpu(), logits.argmax(-1).cpu(), normalize=False)\n","            train_accuracy += train_acc\n","            train_bar.set_postfix({'train_loss': loss.item(), 'train_accuracy': train_accuracy/count})\n","\n","        model.eval()\n","        pred = []\n","        true = []\n","        count = 0\n","        valid_accuracy = 0\n","        valid_bar = tqdm.tqdm(valid_loader)\n","        for i, samples in enumerate(valid_bar):\n","            with torch.no_grad():\n","                output = model(samples)\n","                loss = output['loss']\n","                logits = output['logits']\n","\n","            pred += logits.argmax(-1).tolist()\n","            true += samples['labels'].argmax(-1).tolist()\n","            count += samples['labels'].size(0)\n","            valid_acc = accuracy_score(samples['labels'].argmax(-1).cpu(), logits.argmax(-1).cpu(), normalize=False)\n","            valid_accuracy += valid_acc\n","            valid_bar.set_postfix({'valid_loss': loss.item(),'valid_accuracy': valid_accuracy/count})\n","            \n","        classification_report_val = classification_report(true, pred)\n","        confusion_matrix_val = confusion_matrix(true, pred)\n","        \n","        print(\"\\n\")\n","        print('classification_report_val')\n","        print(classification_report_val)\n","        print(\"\\n\")\n","        print('confusion_matrix_val')\n","        print(confusion_matrix_val)  \n","        print(\"\\n\")\n","            \n","        state_dict = model.state_dict()\n","        save_obj = {\n","            \"model\": state_dict,\n","            \"valid_accuracy\": valid_accuracy/count,\n","            \"classification_report_val\": classification_report_val,\n","            \"confusion_matrix_val\": confusion_matrix_val,\n","        }\n","\n","        save_to = f\"finetune_bert_linear_checkpoint_{epoch+1}.pth\"\n","        torch.save(save_obj, save_to)\n","        print(f'checkpoint saved to:{save_to}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T17:23:19.215680Z","iopub.status.busy":"2024-03-30T17:23:19.215416Z","iopub.status.idle":"2024-03-30T17:23:45.711745Z","shell.execute_reply":"2024-03-30T17:23:45.710460Z","shell.execute_reply.started":"2024-03-30T17:23:19.215658Z"},"trusted":true},"outputs":[],"source":["num_epoch=5\n","train(num_epoch=num_epoch, \n","      train_loader=train_loader, \n","      valid_loader=valid_loader, \n","      model=model, \n","      optimizer=torch.optim.Adam(model.parameters(), lr=5e-5))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4620614,"sourceId":7874152,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
